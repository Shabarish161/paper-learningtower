---
title: "learningtower: an R package for Exploring Standardised Test Scores Across the Globe"
abstract: >
  An abstract of less than 150 words - Discuss what the paper talks about with a little introduction.
draft: true
author: 
  # see ?rjournal_article for more information
  - name: Priya Ravindra Dingorkar
    url: https://www.linkedin.com/in/priya-dingorkar/
    email: priyadingorkar@gmail.com
    affiliation: Monash University
    address:
    - Department Econometrics and Business Statistics
    - Clayton, Australia
  - name: Kevin Y.X. Wang
    affiliation: University of Sydney
    address:
    - Data scientist
    - Illumina, Inc. 
    - School of Mathematics and Statistics 
    - Sydney, Australia
    url: https://kevinwang09.github.io/
    email: kevinwangstats@gmail.com 
  - name: Dianne Cook
    affiliation: Monash University
    address:
    - Department Econometrics and Business Statistics
    - Clayton, Australia
    url: http://dicook.org/
    email: dicook@monash.edu
type: package
creative_commons: CC BY
output: 
  rjtools::rjournal_web_article
header-includes:
    \usepackage{float}
    \floatplacement{figure}{H}
bibliography: learningtower.bib
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      error = FALSE)
```

```{r loadlibraries}
library(rjtools)
library(learningtower)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(patchwork)
library(viridis)
library(plotly)
library(ggplot2)
library(ggbeeswarm)
library(gganimate)
```

# Introduction

The Organization for Economic Cooperation and Development [OECD](OECD - https://www.oecd.org/about/) is a global organization that aims to create better policies for better lives. Its mission is to create policies that promote prosperity, equality, opportunity, and well-being for all. [PISA](PISA - https://www.oecd.org/pisa/) is one of OECD's Programme for International Student Assessment. PISA assesses 15-year-old students' potential to apply their knowledge and abilities in reading, mathematics, and science to real-world challenges. OECD launched this in 1997, it was initially administered in 2000, and it currently includes over [80 nations](https://www.oecd.org/pisa/aboutpisa/pisa-participants.htm). The PISA study, conducted every three years, provides comparative statistics on 15-year-olds' performance in reading, maths, and science. This paper describes how to utilize the `learningtower` package, which offers OECD PISA datasets from 2000 to 2018 in an easy-to-use format. This dataset comprises information on their test results and other socioeconomic factors, as well as information on their schools, infrastructure and the countries participating in the program.

# What is PISA?

PISA assesses the extent to which children approaching the end of compulsory school have learned some of the information and abilities required for full participation in modern society, notably in maths, reading, and science. The examination focuses on reading, mathematics, science, and problem solving. It also assesses students capacity to replicate information and extrapolate from what they have learned and apply that knowledge in unexpected circumstances, both inside and outside of school. This approach reflects the fact that individuals are rewarded in modern economies not for what they know, but for what they can accomplish with what they know. 

This evaluation which is carried out every three years, assists in identifying students' development of knowledge and skills throughout the world, which can provide actionable insights and therefore assist education policymakers. PISA is well known for its distinctive testing characteristics, which include policy orientation, an innovative notion of literacy, relevance to lifelong learning, regularity, and breadth of coverage. PISA is now used as an assessment tool in many regions around the world. In addition to OECD member countries, the survey has been or is being conducted in East, South and Southeast Asia, Central, Mediterranean and Eastern Europe, and Central Asia, The Middle East, Central and South America and Africa. 

For each year of the PISA study, one domain subject is thoroughly examined. In 2018, for example, reading was assessed alongside mathematics and science as minor areas of assessment. The 2012 survey concentrates on mathematics, with reading, science, and problem solving serving as minor evaluation topics. PISA targets a certain age group of students in order to properly compare their performance worldwide. PISA students are aged between 15 years 3 months and 16 years 2 months at the time of the assessment, and have completed at least 6 years of formal schooling. They can enroll in any sort of institution, participate in full-time or part-time education, academic or vocational programs, and attend public, private, or international schools inside the country. Using this age across nations and throughout time allows PISA to compare the knowledge and abilities of people born in the same year who are still in school at the age of 15, irrespective of their diverse schooling.

The PISA test is primarily computer-based and lasts around 2 hours. The examination comprises both multiple choice and free entry questions. Some countries that were not ready for computer-based delivery carried out the testing on paper. Each student may have a unique set of questions. An example of the test may be seen [here](https://www.oecd.org/pisa/test/). PISA assessment areas seek to measure the following aspects of students' literacy in math, reading, and science. The goal of mathematical literacy is to assess students ability to grasp and interpret mathematics in a variety of settings. Reading literacy assesses students' capacity to absorb, apply, analyze, and reflect on texts in order to attain required goals and participate in society. Science literacy is described as the ability to engage with science-related issues and scientific concepts as a reflective citizen.

PISA data is publicly accessible for [download](https://www.oecd.org/pisa/data/). Furthermore, reading the [data documentation](https://www.oecd.org/pisa/data/pisa2018technicalreport/Ch.09-Scaling-PISA-Data.pdf) reveals that the disclosed PISA scores are generated using a sophisticated linear model applied to the data. For each student, several values are simulated. This is known as synthetic data, and it is a popular technique to ensuring data privacy. The data can still be deemed accurate within the mean, variance, and stratum used in the original data's modelling. In addition, the PISA website provides the data in SPSS and SAS format, which can limit accessibility due to the commercial nature of these software. Furthermore, all questions are assigned with unique IDs within each year of the PISA study, but do not always agree across the different years. This data has now been curated and simplified into a single R package called `learningtower`, which contains all of the PISA scores from the years 2000 to 2018.

# Data Compilation

Each developer at the ROpenSci OzUnconf was assigned to curate a specific year of the PISA study. Data on the participating students and schools were first downloaded from the PISA website, in either SPSS or SAS format. The data were read into an R environment with the exception of the year 2000 and 2003. Due to formatting issues, the data for these two particular years were first read using SPSS and then exported into compatible `.sav` files. After some data cleaning and wrangling with the appropriate script, the variables of interest were re-categorised and saved as RDS files. One major challenge faced by the developers was to ensure the consistency of variables over the  years. For example, a student's mother's highest level of education was never recorded in 2000, but it was categorised as "ST11R01" between 2003 and 2012 and "ST005Q01TA" between 2015 and 2018. Such a problem was tackled manually by curating these values as an integer variable named "mother_educ" in the output data. These final RDS file for each PISA year were then thoroughly vetted and made available in a separate [GitHub repository](https://github.com/kevinwang09/learningtower_masonry).

# What is `learningtower`?

['learningtower'](https://cran.r-project.org/web/packages/learningtower/index.html) is an easy-to-use R package that provides quick access to a variety of variables using OECD PISA data collected over a three-year period from 2000 to 2018. This dataset includes information on the PISA test scores in mathematics, reading, and science. Furthermore, these datasets include information on other socioeconomic aspects, as well as information on their school and its facilities, as well as the nations participating in the program. 

The motivation for developing the `learningtower` package was sparked by the announcement of the PISA 2018 results, which caused a collective wringing of hands in the Australian press, with headlines such as ["Vital Signs: Australia's slipping student scores will lead to greater income inequality"](https://theconversation.com/vital-signs-australias-slipping-student-scores-will-lead-to-greater-income-inequality-128301) and ["In China, Nicholas studied maths 20 hours a week. In Australia, it's three"](https://www.smh.com.au/education/in-china-nicholas-studied-maths-20-hours-a-week-in-australia-it-s-three-20191203-p53ggv.html). That's when several academics from Australia, New Zealand, and Indonesia decided to make things easier by providing easy access to PISA scores as part of the [ROpenSci OzUnconf](https://ozunconf19.ropensci.org/), which was held in Sydney from December 11 to 13, 2019. The data from this survey, as well as all other surveys performed since the initial collection in 2000, is freely accessible to the public. However, downloading and curating data across multiple years of the PISA study could be a time consuming task. As a result, we have made a more convenient subset of the data freely available in a new R package called `learningtower`, along with sample code for analysis. 

The `learningtower` package primarily comprised of three datasets: `student`, `school`, and `countrycode.` The `student` dataset includes results from triennial testing of 15-year-old students throughout the world. This dataset also includes information about their parents' education, family wealth, gender, and presence of computers, internet, vehicles, books, rooms, desks, and other comparable factors. Due to the size limitation on CRAN packages, only a subset of the student data can be made available in the downloaded package. These subsets of the student data, known as the `student_subset_yyyy` (`yyyy` being the specific year of the study) allow uses to quickly load, visualise the trends in the full data. The full student dataset can be downloaded using the `load_student()` function included in this [package.](https://kevinwang09.github.io/learningtower/) The `school` dataset includes school weight as well as other information such as school funding distribution, whether the school is private or public, enrollment of boys and girls, school size, and similar other characteristics of interest of different schools these 15-year-olds attend around the world. The `countrycode` dataset includes a mapping of a country/region's ISO code to its full name.

`learningtower` developers are committed to providing R users with data to analyse PISA results every three years. Our package's future enhancements include updating the package every time additional PISA scores are announced. Note that, in order to account for post COVID-19 problems, OECD member nations and associates decided to postpone the PISA 2021 evaluation to 2022 and the PISA 2024 assessment to 2025.

# Example Analysis


In this section we will illustrate how the `learningtower` package can be utilized to answer some research questions by applying various methodologies and statistical computations on the `learningtower` datasets.

We will solely utilize the 2018 PISA data and scores for illustrative purposes throughout the example analysis section. During the post-development phase, the `learningtower` developers collectively decided to answer a few intriguing questions on the PISA data and see if we could identify any interesting trends or insights utilizing this dataset. Some of these questions include if there is any significant gender difference between girls and boys whos perform is better in any of the three areas of mathematics, reading, and science. Do the various socioeconomic characteristics reflected in the student data have a substantial impact on the scores of these 15-year-olds. Furthermore, we will delve into Australia's score history and temporal trend to uncover some noteworthy trends that Australia has observed as a result of its participation in the PISA experiment.

Gender gaps have always been a topic of interest among researchers, and when it comes to PISA data and scores of 15-year-old students around the world, uncovering patterns based on their gender would help gain meaningful insights in the field of education for various education policymakers around the world. Based on the 2018 PISA results, let us see if there is a major gender disparity between girls and boys throughout the world in mathematics, reading, and science. To begin, we will create a 'data.frame' that stores the weighted average maths score for each nation as well as the various regions of the countries organized by country gender. [Survey weights](https://www.oecd.org/pisa/data/2015-technical-report/PISA-2015-Technical-Report-Chapter-8-Survey-Weighting.pdf) are critical and must be used in the analysis to guarantee that each sampled student accurately represents the total number of pupils in the PISA population. In addition, we compute the gender difference between the two averages. To demonstrate the variability in the mean estimate, we use bootstrap sampling with replacement on the data and compute the same mean difference estimate. For each nation, the empirical 90 percent confidence intervals are presented. The same process is used for reading and science test scores.


# Gender Analysis

```{r gendergap, fig.height = 14, fig.width = 6, fig.align = "center", fig.pos="H"}

student_2018 <- load_student("2018")
data(countrycode, package = "learningtower")

student_country <- left_join(student_2018, countrycode, by = "country")


#removing na values
math_pisa_2018_data <- student_country %>% 
  filter(!is.na(gender), !is.na(math), !is.na(stu_wgt))


#avg math scores and diff 
math_diff_df <- math_pisa_2018_data %>%
  group_by(gender, country_name) %>% 
  summarise(avg = weighted.mean(math, stu_wgt)) %>%
  ungroup() %>%
  pivot_wider(country_name, 
              names_from = gender,
              values_from = avg) %>%
mutate(diff = female - male, 
       country_name = fct_reorder(country_name, diff))


#Bootstrap
set.seed(2020)
boot_ests_math <- map_dfr(1:100, ~{
  math_pisa_2018_data %>%
  group_by(country_name, gender) %>%
  sample_n(size = n(), replace = TRUE) %>%
  summarise(avg = weighted.mean(math, stu_wgt), .groups = "drop") %>%
  ungroup() %>%
  pivot_wider(country_name, names_from = gender, values_from = avg) %>%
  mutate(diff = female - male, country_name = fct_reorder(country_name, diff)) %>%
  mutate(boot_id = .x) 
})

#Confidence Intervals
math_diff_conf_intervals <- boot_ests_math %>%
  group_by(country_name) %>%
  summarise(lower = sort(diff)[5],
  upper = sort(diff)[95])%>%
  left_join(math_diff_df, by = "country_name") %>%
  mutate(country_name = fct_reorder(country_name, diff)) %>%
  mutate(score_class = case_when(lower < 0 & upper < 0 ~ "red", 
                           lower < 0 & upper > 0 ~ "blue",
                           lower > 0 & upper > 0 ~ "green"))

#Math Plot
math_plot <- ggplot(math_diff_conf_intervals, 
                    aes(diff, country_name, 
                        col = score_class)) +
  scale_colour_brewer(palette = "Dark2") +
  geom_point() + geom_errorbar(aes(xmin = lower, xmax = upper)) +
  geom_vline(xintercept = 0, color = "red") +
  labs(y = "",
  x = "Maths Scores Girls - Boys", 
  title = "Maths") +
  theme(legend.position="none") + 
  annotate("text", x = 10.5, y = 1, label = "Girls") +
  annotate("text", x = -10.5, y = 1, label = "Boys") +
  scale_x_continuous(breaks = pretty(math_diff_conf_intervals$diff), 
                     labels = abs(pretty(math_diff_conf_intervals$diff)))
```


```{r}
#removing na values
read_pisa_2018_data <- student_country %>%  
  filter(!is.na(gender)) %>% 
  filter(!is.na(read)) %>% 
  filter(!is.na(stu_wgt)) 

#avg math scores and diff 
read_diff_df <- read_pisa_2018_data %>%
  group_by(gender, country_name) %>%
  summarise(avg = weighted.mean(read, stu_wgt), .groups = "drop") %>%
  ungroup() %>%
  pivot_wider(country_name, names_from = gender,
  values_from = avg) %>%
  mutate(diff = female - male,
  country_name = fct_reorder(country_name, diff))

#Bootstrap
boot_ests_read <- map_dfr(1:100, ~{
  read_pisa_2018_data %>%
  group_by(country_name, gender) %>%
  sample_n(size = n(), replace = TRUE) %>%
  summarise(avg = weighted.mean(read, stu_wgt)) %>%
  ungroup() %>%
  pivot_wider(country_name, names_from = gender, values_from = avg) %>%
  mutate(diff = female - male, country_name = fct_reorder(country_name, diff)) %>%
  mutate(boot_id = .x)
})

#CI
read_diff_conf_intervals <- boot_ests_read %>%
  group_by(country_name) %>%
  summarise(lower = sort(diff)[5],
  upper = sort(diff)[95])%>%
  left_join(read_diff_df, by = "country_name") %>%
  mutate(country_name = fct_reorder(country_name, diff)) %>%
  mutate(score_class = case_when(lower < 0 & upper < 0 ~ "red", 
                           lower < 0 & upper > 0 ~ "blue",
                           lower > 0 & upper > 0 ~ "green"))


read_plot <- ggplot(read_diff_conf_intervals, 
                    aes(diff, country_name, 
                        col = score_class)) + 
  scale_colour_brewer(palette = "Dark2") +
  geom_point() + geom_errorbar(aes(xmin = lower, xmax = upper)) +
  geom_vline(xintercept = 0, color = "red") +
  labs(y = "",
  x = "Reading Scores Girls - Boys", 
  title = "Reading") +
  theme(legend.position="none") +
  annotate("text", x = 20, y = 1, label = "Girls") +
  scale_x_continuous(breaks = pretty(math_diff_conf_intervals$diff), 
                     labels = abs(pretty(math_diff_conf_intervals$diff)))
```



```{r}
#removing na values
sci_pisa_2018_data <- student_country %>% 
  filter(!is.na(gender)) %>% 
  filter(!is.na(science)) %>% 
  filter(!is.na(stu_wgt)) 

#avg math scores and diff 
sci_diff_df <- sci_pisa_2018_data %>%
  group_by(gender, country_name) %>%
  summarise(avg = weighted.mean(science, stu_wgt), .groups = "drop") %>%
  ungroup() %>%
  pivot_wider(country_name, names_from = gender,
  values_from = avg) %>%
  mutate(diff = female - male,
  country_name = fct_reorder(country_name, diff))


#Bootstrap
boot_ests_sci <- map_dfr(1:100, ~{
  sci_pisa_2018_data %>%
  group_by(country_name, gender) %>%
  sample_n(size = n(), replace = TRUE) %>%
  summarise(avg = weighted.mean(science, stu_wgt)) %>%
  ungroup() %>%
  pivot_wider(country_name, names_from = gender, values_from = avg) %>%
  mutate(diff = female - male, country_name = fct_reorder(country_name, diff)) %>%
  mutate(boot_id = .x)
})

#Bootstrap using R: Part 3
sci_diff_conf_intervals <- boot_ests_sci %>%
  group_by(country_name) %>%
  summarise(lower = sort(diff)[5],
  upper = sort(diff)[95])%>%
  left_join(sci_diff_df, by = "country_name") %>%
  mutate(country_name = fct_reorder(country_name, diff)) %>%
  mutate(score_class = case_when(lower < 0 & upper < 0 ~ "red", 
                           lower < 0 & upper > 0 ~ "blue",
                           lower > 0 & upper > 0 ~ "green"))


sci_plot <- ggplot(sci_diff_conf_intervals, 
                    aes(diff, country_name, 
                        col = score_class)) +
  scale_colour_brewer(palette = "Dark2") +
  geom_point() + geom_errorbar(aes(xmin = lower, xmax = upper)) +
  geom_vline(xintercept = 0, color = "red") +
  labs(y = "",
  x = "Science Scores Girls - Boys", 
  title = "Science") +
  theme(legend.position="none") + 
  annotate("text", x = 10, y = 1, label = "Girls") +
  annotate("text", x = -5, y = 1, label = "Boys") +
  scale_x_continuous(breaks = pretty(math_diff_conf_intervals$diff), 
                     labels = abs(pretty(math_diff_conf_intervals$diff)))
```


```{r score-differences, fig.cap ="The chart above depicts the gender gap difference in 15-year-olds' in math, reading, and science results in 2018. The scores to the right of the red line represent the performances of the girls, while the scores to the left of the red line represent the performances of the boys. One of the most intriguing conclusions we can get from this chart is that in the PISA experiment in 2018, girls from all nations outperformed boys in reading.", fig.width=12, fig.height=16, fig.pos = "H", out.width="100%", layout="l-body"}
math_plot + read_plot + sci_plot
```

Figure \@ref(fig:score-differences) illustrates the global disparities in mean math, reading, and science outcomes Before we get to the plot conclusion, let's have a look at the variables that have been plotted. The red line here indicates a reference point, and all of the scores to the right of the red line show the scores of girls in math, reading, and science. Similarly, the scores on the left side of this line indicate the scores of boys in the three disciplines. Based on figure \@ref(fig:score-differences), because most math estimates and confidence intervals lie to the left of the red line, we may conclude that most boys outperformed girls in math. In nations such as Morocco, Netherlands, Slovenia, Poland, Bulgaria, and Greece, there is almost no gender difference in math outcomes. When we look at the reading scores, we notice a really interesting detail: girls outpaced boys in reading in all countries in 2018. The highest reading scores were achieved by girls from Qatar, the United Arab Emirates, and Finland. Looking further into the science plot, we see an unexpected pattern: most nations have very little gender difference in science scores, implying that most boys and girls perform equally well in science. Boys from Peru, Colombia, and regions of China perform really well in science and girls from Qatar, the United Arab Emirates, and Jordan are the top scores for science. Figure \@ref(fig:score-differences) helps us depicts the gender gap in math, reading, and science for all nations and regions that took part in the 2018 PISA experiment.


We gathered meaningful insights about the gender gap between girls and boys throughout the world from the above figure \@ref(fig:score-differences) because this is a geographical research communication topic, the findings will help us better comprehend the score differences in the three educational disciplines using globe maps. Let us continue to investigate and discover patterns and correlations using this, map visualisation. To illustrate the gender gap difference between girls and boys throughout the world, we utilize the `map_data` function to get the latitude and longitude coordinates needed to construct a map for our data. We connect these latitude and longitude coordinates to our PISA data and render the world map using `geom_polygon` function wrapped within `ggplot2`.


```{r}
theme_map <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(),
    axis.line = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.border = element_blank(),
    panel.grid = element_blank()
  )
}
```


```{r}
math_map_data <- math_diff_conf_intervals  %>% 
  dplyr::mutate(country_name = case_when(
                country_name == "Brunei Darussalam" ~ "Brunei",
                country_name == "United Kingdom" ~ "UK",
                country_name %in% c("Macau SAR China", "B-S-J-Z (China)", 
                                    "Hong Kong SAR China") ~ "China",
                country_name == "Korea" ~ "South Korea",
                country_name == "North Macedonia" ~ "Macedonia",
                country_name == "Baku (Azerbaijan)" ~ "Baku",
                country_name %in% c("Moscow Region (RUS)", "Tatarstan (RUS)",
                "Russian Federation") ~ "Russia",
                country_name == "Slovak Republic" ~ "Slovakia",
                country_name == "Chinese Taipei" ~ "Taiwan",
                country_name == "United States" ~ "USA",
                TRUE ~ as.character(country_name)))

world_map <- map_data("world") %>% 
  filter(region != "Antarctica") %>% 
  fortify() %>% 
  rename(country_name = region)

math_world_data <- full_join(math_map_data,
                        world_map,
                        by = "country_name") 

math_world_data <- math_world_data %>% 
  rename(Country = country_name, 
         Maths = diff) %>% 
  mutate(Maths = round(Maths, digits = 2))


math_map_plot <- ggplot(math_world_data, 
                        aes(x = long, y = lat, group = group)) +
                  geom_polygon(aes(fill= Maths,  
                                   label = Country)) +
                  theme_map() +
                  labs(title = "World Map displaying Maths Scores Difference") +
                  scale_fill_viridis(option = "D")
```



```{r}
# Maps in R - Reading Maps
read_map_data <- read_diff_conf_intervals %>% 
  dplyr::mutate(country_name = case_when(
                country_name == "Brunei Darussalam" ~ "Brunei",
                country_name == "United Kingdom" ~ "UK",
                country_name %in% c("Macau SAR China", "B-S-J-Z (China)", 
                                    "Hong Kong SAR China") ~ "China",
                country_name == "Korea" ~ "South Korea",
                country_name == "North Macedonia" ~ "Macedonia",
                country_name == "Baku (Azerbaijan)" ~ "Baku",
                country_name %in% c("Moscow Region (RUS)", "Tatarstan (RUS)",
                "Russian Federation") ~ "Russia",
                country_name == "Slovak Republic" ~ "Slovakia",
                country_name == "Chinese Taipei" ~ "Taiwan",
                country_name == "United States" ~ "USA",
                TRUE ~ as.character(country_name)))

world_map <- map_data("world") %>% 
  filter(region != "Antarctica") %>% 
  fortify() %>% 
  rename(country_name = region)

read_world_data <- full_join(read_map_data,
                        world_map,
                        by = "country_name") 

read_world_data <- read_world_data %>% 
  rename(Country = country_name, 
         Reading = diff) %>% 
  mutate(Reading = round(Reading, digits = 2))



read_map_plot <- ggplot(read_world_data, 
                        aes(x = long, y = lat, group = group)) +
                  geom_polygon(aes(fill= Reading, 
                                   label = Country)) +
                  theme_map() +
                  labs(title = "World Map displaying Reading Scores Difference") +
                  scale_fill_viridis(option = "C")
```
                  



```{r}
sci_map_data <- sci_diff_conf_intervals %>% 
  dplyr::mutate(country_name = case_when(
                country_name == "Brunei Darussalam" ~ "Brunei",
                country_name == "United Kingdom" ~ "UK",
                country_name %in% c("Macau SAR China", "B-S-J-Z (China)", 
                                    "Hong Kong SAR China") ~ "China",
                country_name == "Korea" ~ "South Korea",
                country_name == "North Macedonia" ~ "Macedonia",
                country_name == "Baku (Azerbaijan)" ~ "Baku",
                country_name %in% c("Moscow Region (RUS)", "Tatarstan (RUS)",
                "Russian Federation") ~ "Russia",
                country_name == "Slovak Republic" ~ "Slovakia",
                country_name == "Chinese Taipei" ~ "Taiwan",
                country_name == "United States" ~ "USA",
                TRUE ~ as.character(country_name)))

world_map <- map_data("world") %>% 
  filter(region != "Antarctica") %>% 
  fortify() %>% 
  rename(country_name = region)

sci_world_data <- full_join(sci_map_data,
                        world_map,
                        by = "country_name") 

sci_world_data <- sci_world_data %>% 
  rename(Country = country_name, 
         Science = diff)  %>% 
  mutate(Science = round(Science, digits = 2))

sci_map_plot <- ggplot(sci_world_data, 
                        aes(x = long, y = lat, group = group)) +
                  geom_polygon(aes(fill= Science, 
                                   label = Country)) +
                  theme_map() +
                  labs(title = "World Map displaying Science Scores Difference") +
                  scale_fill_viridis(option = "G")
```


```{r plotly-maps, fig.cap="Interactive maps that show the gender gap in math, reading, and science results between girls and boys throughout the world. The interactive aspect of the map allows one to move their cursor around the global map, which displays the country name as well as the gender gap scores between girls and boys. A positive score for a country indicates that girls outperformed boys in that country, whereas a negative score for a country difference indicates that boys outperformed girls in that country. The diverging colour scale makes it possible to interpret the range of scores and the also helps us intrepret the gender gap difference among these students across the globe. The reading scores all have positive values, indicating that girls outperform boys across the world in the year 2018.", fig.pos="H", fig.height=4, fig.width=12, out.width="100%", layout="l-body", include=knitr::is_html_output(), eval=knitr::is_html_output()}
gmp1 <- ggplotly(math_map_plot)
gmp2 <- ggplotly(read_map_plot)
gmp3 <- ggplotly(sci_map_plot)
# fig <- subplot(gmp1, gmp2, gmp3, nrows = 3)
# s1 <- subplot(gmp1, gmp2, nrows =2)
gmp1
gmp2
gmp3
```



```{r ggplot-maps, fig.cap="Maps that show the gender gap in math, reading, and science results between girls and boys throughout the world. The diverging colour scale makes it possible to interpret the range of scores and the also helps us intrepret the gender gap difference among these students across the globe. The legend for each discipline enables interpretation of the score differential for each subject across all maps. A positive score for a country indicates that girls outperformed boys in that country, whereas a negative score for a country difference indicates that boys outperformed girls in that country.The reading scores are all positive, suggesting that girls outperform boys globally in the year 2018.", fig.height=9, fig.pos="H", out.width="100%", layout="l-body", include=knitr::is_latex_output(), eval=knitr::is_latex_output()}
math_map_plot/read_map_plot/sci_map_plot
```



In the graphic `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(fig:plotly-maps)', '\\@ref(fig:ggplot-maps)'))`, we have used maps to show the gender gap difference between girls and boys in math, reading, and science in 2018. Map visualization aids in the comprehension of large volumes of data at a look and in a more efficient manner. Increases the ability to compare outcomes across many geographies at a glance. In the illustration, we see both positive and negative score difference scale ranges in all three maps. A positive country score indicates that girls outperformed boys in that country, whereas a negative country score shows that boys outscored girls in that country. Observing the legends of these maps further helps us deduce the large gender discrepancy between girls and boys. Looking at these three maps together, we can see that the most gender difference can be seen in math and reading scores, where most boys around the world outperform girls in the subject of mathematics, whereas all positive reading scores indicate that all girls around the world outperformed boys in reading in 2018. Furthermore, there is less of a gender disparity in science scores. Furthermore, the separate diverging scale for each subject aids in the interpretation of the gender gap score transferred to different nations. It also assists us in identifying the nations that took part in the PISA experiment. The grey colour for different geographic locations across the maps in figure `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(fig: plotly-maps)', '\\@ref(fig:ggplot-maps)'))` indicates that these regions were not a part of the PISA experiment in year 2018. 

As a result, in this section, we have seen the gender gap scores and striking trends between 15-year-old girls and boys in math, reading, and science. Our main conclusion from this gender study is the performance of girls in reading. The fewer gender disparity evident in science scores, and the majority of boys perform better than girls in mathematics.



# Socioeconomic Factors Analysis 


Socioeconomic status is an economic and sociological complete measure of a person's work experience, economic access to resources, and social standing in relation to others. Do these socioeconomic factors influence students' academic performance? In this section, we will investigate if different socioeconomic factors owned by a family have a significant impact on a student's academic performance. The student dataset in the `learningtower` package is made up of scores from triennial testing of 15-year-olds throughout the world. This dataset also includes information about their parents' education, family wealth, gender, and ownership of computers, internet, cars, books, rooms, desks, and dishwashers. In this section, we will mainly explore intriguing figures and derive some fascinating aspects of the influence of a few socioeconomic factors on student performance in math, reading, and science. Before we go on to our socioeconomic determinants and their impact on students, figure \@ref(fig:corr-plot) shows how the math, reading, and science scores are strongly positively related to one another.

```{r}
p1 <- ggplot(data = student_country, 
             aes(x = math, y = read)) +
  geom_hex() + 
  labs(x = "Math Scores", 
       y = "Reading Scores") +
  theme(legend.position="none")

p2 <- ggplot(data = student_country, 
             aes(x = math, y = science)) +
  geom_hex() + 
  labs(x = "Math Scores", 
       y = "Science Scores") +
  theme(legend.position = "bottom", 
        legend.box = "horizontal", 
        legend.text=element_text(size=7.2))

p3 <- ggplot(data = student_country, 
             aes(x = read, y = science)) +
  geom_hex() + 
  labs(x = "Reading Scores", 
       y = "Science Scores") +
  theme(legend.position="none")
```

```{r corr-plot, fig.cap ="The scatterplot displays the relationship between math, reading, and science scores for all PISA countries that participated in the experiment in 2018. This scatterplot shows that all three subjects have a significant and positive correlation with one another.", fig.width=9, fig.pos = "H", out.width="100%", layout="l-body"}
p1+p2+p3
```

We plotted all three scores against each other in the figure \@ref(fig:corr-plot) to understand the relationship between them. This data allows us to deduce that math, science, and reading scores are positively and significantly connected with one another, implying that when we inspect and analyze the many socioeconomic determinants, we would get comparable outcomes with each score and influence of desire component. As a result of seeing this substantially positive association between all three scores for all countries that participated in the PISA experiment in 2018, the `learningtower` developers decided to show the effect of socioeconomic variables on average math scores only because of the significant association between present reading and science scores would tend to show similar patterns as well. Let us further explore the impact of the a few socioeconomic factors on the students score.

Parents qualification is and will always be a vital element of childhood development. As previously stated, the student dataset in the package includes information regarding the parents qualification. In this section, we will investigate if both the mother's and father's qualifications have a significant impact on the child's performance. The mother and father qualifying variables are originally recorded in the package at distinct levels that are less than ISCED1 equivalent to ISCED 0, ISCED 1, ISCED 2, ISCED 3A and ISCED 3B, C. The International Standard Classification of Education, (ISCED) who decides and classifies these levels, where level 0 indicates pre-primary education or no education at all, level 1 indicates primary education or the first stage of basic education, level 2 indicates lower secondary education or the second stage of basic education, and level 3 indicates upper secondary education. ISCED level 3 have been further classified into three distinct levels, with ideally very little difference in their classification. This may also be found in the publication [Classifying Educational Programmes](https://www.oecd.org/education/1841854.pdf) published by ISCED. To determine the impact of parents qualification we first create a `data.frame` that is first categorized by the various countries and regions and grouping by the father's amd mother qualification as well. We next compute the average weighted weighted mean of math scores while accounting for student weights. Furthermore, we restructured this variable based on the multiple levels of classification, dividing it into four unique levels of education, namely early childhood, primary, lower, and secondary education. Furthermore, we display the weighted math average versus qualification for both the mother and father using the `geom_quasirandom` function wrapped within `ggplot2.`

```{r}
student_country_data <- left_join(student_2018,
                                  countrycode,
                                  by = "country")


father_qual_math_read_sci_data <- student_country_data %>%
  group_by(country_name, father_educ) %>%
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>%
dplyr::mutate(father_educ = recode_factor(father_educ,
                "less than ISCED1" = "Early Childhood",
                "ISCED 1" = "Primary",
                "ISCED 2" = "Lower Secondary",
                "ISCED 3A" = "Upper Secondary",
                "ISCED 3B, C" = "Upper Secondary",
                .ordered = TRUE)) %>%
  na.omit() %>%
  rename(`Father's Education` = father_educ)




mother_qual_math_read_sci_data <- student_country_data %>%
  group_by(country_name, mother_educ) %>%
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>% 
dplyr::mutate(mother_educ = recode_factor(mother_educ,
                "less than ISCED1" = "Early Childhood",
                "ISCED 1" = "Primary",
                "ISCED 2" = "Lower Secondary",
                "ISCED 3A" = "Upper Secondary",
                "ISCED 3B, C" = "Upper Secondary",
                .ordered = TRUE)) %>%
  na.omit() %>%
  rename(`Mother's Education` = mother_educ)


mother_qual_math <- ggplot(mother_qual_math_read_sci_data, 
       aes(x=`Mother's Education`,
           y=math_avg,
           col=`Mother's Education`)) +
  geom_quasirandom(size = 1.7, 
             cex = 3) +
  geom_line(aes(group = country_name), 
            size=0.5, alpha=.36) +
  scale_fill_viridis(discrete = TRUE,
                     option = "A",
                      alpha=0.2) +
    stat_summary(fun.y = median, 
                 fun.ymin = median, 
                 fun.ymax = median,
                 geom = "crossbar", 
                 width = 0.5, 
                 col = "black") +
  theme(legend.position="none",
      plot.title = element_text(size=11)) +
    labs(y = "Average Mathematics Score",
         x = "Mother's Qualification",
         title = "Maths Scores and Mother's Qualification")

father_qual_math <- ggplot(father_qual_math_read_sci_data, 
       aes(x=`Father's Education`,
           y=math_avg,
           col=`Father's Education`)) +
  geom_quasirandom(size = 1.7, 
             cex = 3) +
  geom_line(aes(group = country_name), 
            size=0.5, alpha=.36) +
  scale_fill_viridis(discrete = TRUE,
                     option = "A",
                      alpha=0.2) +
    stat_summary(fun.y = median, 
                 fun.ymin = median, 
                 fun.ymax = median,
                 geom = "crossbar", 
                 width = 0.5, 
                 col = "black") +
  theme(legend.position="none",
      plot.title = element_text(size=11)) +
    labs(y = "Average Mathematics Score",
         x = "Father's Qualification",
         title = "Maths Scores and Father's Qualification")
```

```{r qual-plot, fig.cap ="The influence of parents' education on their children's academic success. When the parents have attained higher levels of education, the figure shows a significant increase in scores and an increase in the median of scores for each category. When compared to the parents who have lesser levels of education qualifications. Parents upper secondary education or equivalent qualifications children tend to scoree higer in weighted average math scores.", fig.width= 16, fig.height= 8, fig.pos = "H", out.width="100%", layout="l-body"}
father_qual_math + mother_qual_math
```

The figure \@ref(fig:qual-plot) depicts the impact of mothers' and fathers' qualifications on students academic performance. The figure \@ref(fig:qual-plot) allows us to deduce a very important and remarkable insight in which we see a constant increase in the students' academic performance when both mother and father qualifications shift towards higher levels of education. The bold horizontal black lines that we see in each category for mother's and father's qualification here represent the category's median score. As the parent attains better qualifications, we notice an increasing trend in these medians for each category. Taking a closer look at the figure \@ref(fig:qual-plot), we can see that there is a considerable boost in scores when both the mother and father have upper secondary education. Furthermore, utilizing `the geom_quasirandom` function makes this plot more accessible and understandable by providing a way to offset points inside categories to prevent overplotting. Thus, we can clearly see that both the mother's and father's qualifications have a significant influence on the student's academic performance, with the more educated the parent, the more likely their offspring are to perform well academically.

Television is one of humanity's greatest inventions; it is one of the assets that has had a significant impact and influence on humans. In this segment of the article, we investigate the influence of television in many countries, as well as whether this technology has a significant impact on students' academic performance. The television variables that are recorded in the student dataset is a factor variable that records whether or not the students participating in this study have a television and, if they do, the quantity of televisions per family is recorded via the PISA survey. Furthermore, because we are interested in researching the impact of these television on the students' scores, we have re factored the television variables and designated four levels: No TV, 1 TV, 2 TVs, or 3+TVs. We are also interested in visualising the confidence intervals for each of these levels in order to determine the uncertainty of the results at each level. We begin with initially creating a data.frame that is grouped by nation and the number of television stations in each country. We fitted a linear model to the math average and television categories for each country in the 2018 PISA data. And finally plot the television impact as per the slope.


```{r}
z_star_95 <- qnorm(0.975) 

tv_math_data <- student_country_data %>% 
  group_by(country_name, television) %>% 
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE), 
                   lower = weighted.mean(math, w = stu_wgt, na.rm = TRUE) - z_star_95 * (sd(math, na.rm = TRUE)) / sqrt(length(math)), 
                   upper = weighted.mean(math, w = stu_wgt, na.rm = TRUE) + z_star_95 * (sd(math, na.rm = TRUE)) / sqrt(length(math))) %>% 
  dplyr::mutate(television = recode_factor(television,
                 "0" = "No TV",
                 "1" = "1 TVs",
                 "2" = "2 Tvs",
                 "3+" = "3+ TVs", 
                .ordered = TRUE)) %>%
  na.omit() %>% 
  dplyr::select(television, 
                math_avg, 
                lower, 
                upper)



linear_model <- function(y, x){
  coef(lm(y ~ x))[2]
}

tv_plot <- tv_math_data %>%
  group_by(country_name) %>%
  mutate(slope = linear_model(math_avg, television)) %>%
  ungroup() %>%
  mutate(country_name = fct_reorder(country_name, slope)) %>%
  ggplot(aes(x=television, y=math_avg)) + 
  geom_point(size=1.8) +
  geom_line(aes(group = country_name)) +
  geom_errorbar(aes(ymin = lower, ymax = upper, group = country_name),
                width=0.18, colour="orange", alpha=0.3, size=1.53) +
  facet_wrap(~country_name, ncol = 5, scales = "free") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) +
  labs(x = "Possession of Television",
       y = "Average Mathematics Score")
```



```{r tv-plot, fig.cap ="The impact of television on student performance is a contentious issue, however in this graph, we have examined the effects of television on student performance using statistical methods. The counties are arranged according to the slope of the linear model fitted for the math average score against the various levels of television. We can observe that television has the greatest influence on performance in a select countries, such as Lebanon, whilst it has the least impact in Slovenia. The confidence interval suggests that there is an uncertainty of the scores when a household does not own a television in the majority of the nations that participated in the PISA experiment in the year 2018", fig.height=21, fig.width=12, fig.pos = "H", out.width="100%", layout="l-body"}
tv_plot
```


In the figure \@ref(fig:tv-plot), we can see highly striking patterns as well as a significant influence of television on student academic performance. We have arranged the nations in the figure \@ref(fig:tv-plot) according to the slope of math average scores fitted against the different levels of television described previously. Slovenia, the Netherlands, Switzerland, Hungary, and Poland have a lower influence of television on student performance, whereas Portugal, Panama, Peru, and Lebanon have a rising tendency and therefore a larger impact of television on student performance. Furthermore, the confidence interval plotted in the figure \@ref(fig:tv-plot) show that there is a lot of uncertainty in the level of scores when a household does not possess a TV in the majority of the countries. Furthermore, when the slope of television increases in countries, the confidence interval of such countries becomes narrower. hence depending on your wealth and where you live, television can be a valuable asset. since it has a variable effect on a student's academic performance

We've always heard and read that books play an important role in early childhood because they assist learners develop emotional intelligence and creativity. However, the developers of `learningtower` pacakage intended to invest if books, has a significant influence on the students score. The book variable is recorded in the student dataset has been categorized in the following levels 0-10, 11-25, 26-100, 101-200, and more than 500 books. We will do a similar investigation as we did when we investigated the effct of television. First, we construct a dataframe that is grouped by the different levels of books and countries. In addition, we calculated the confidence interval using the method to account for the uncertainty associated with the score. We subsequently use a linear model with the average math score and each level of book categories to derive a coefficient or slope for each country. Finally, plot the location and score estimations for each country, ordered according to slope.



## Book Plot

```{r}
z_star_95 <- qnorm(0.975) 

book_math_read_sci_data <- student_country_data %>% 
  group_by(country_name, book)  %>% 
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE), 
                   bk_lower = weighted.mean(math, w = stu_wgt, na.rm = TRUE) - z_star_95 * (sd(math, na.rm = TRUE)) / sqrt(length(math)), 
                   bk_upper = weighted.mean(math, w = stu_wgt, na.rm = TRUE) + z_star_95 * (sd(math, na.rm = TRUE)) / sqrt(length(math)))  %>% 
  dplyr::mutate(book = recode_factor(book, 
                                     "0-10" = "0-10",
                                     "11-25" = "11-25", 
                                     "26-100" = "26-100",
                                     "101-200" = "101-200",
                                     "201-500" = "201-500",
                                     "more than 500" = "500+",
                                     .ordered = TRUE)) %>% 
  na.omit() %>% 
  rename(Number_of_Books = book)

linear_model <- function(y, x){
  coef(lm(y ~ x))[2]
}


book_plot <- book_math_read_sci_data %>%
  group_by(country_name) %>%
  mutate(slope = linear_model(math_avg, Number_of_Books)) %>%
  ungroup() %>%
  mutate(country_name = fct_reorder(country_name, slope)) %>%
  ggplot(aes(x=Number_of_Books, y=math_avg)) + 
  geom_point(size=1.8) +
  geom_line(aes(group = country_name)) +
  geom_errorbar(aes(ymin = bk_lower, ymax = bk_upper, group = country_name),
                width=0.18, colour="darkred", alpha=0.3, size=1.53) +
  facet_wrap(~country_name, ncol = 5, scales = "free") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "Possession of Books",
       y = "Average Mathematics Score")
```

```{r book-plot, fig.cap ="Books are man's best friend. In this graph, we're looking at the influence that the number of books each family has. This graph shows that the more the quantity of books that a households owns, the greater the effect is observed in the student average math scores. We find that countries such as the Dominican Republic and Panama have a lower influence of books when compared to Luxembourg and Hungary.", fig.height=21, fig.width=12, fig.pos = "H", out.width="100%", layout="l-body"}
book_plot
```


In the figure \@ref(fig:book-plot), we can see the different countires arranged by slope and their correlation with math score estimation for each of the book categories. Taking a detailed look at the figure \@ref(fig:book-plot), we deduced that the more books a family possesses, the more likely it is that its children will perform well academically. Looking at the graph, we can notice a rising tendency as the quantity of books per household increases. Furthermore, we see a decline in the score when the category contains more than 500 books, owing to the lack of data in such categories. Because there are extremely few households with more than 500 books. In this scenario, we will examine the confidence intervals of our plots to better understand the bottom and upper bounds of the math score estimation. The confidence intervals in each of the categories are not particularly broad. In addition, arranging the graph by slope allows us to understand the impact of books in different countries. Despite the fact that most countries have a significant influence on books per home, we can see in this graph that most countries have a significant impact on books per household. We may state that the Dominican Republic, Indonesia, and Panama have less books than the countries of Luxembourg, Germany, and Hungary. As a result, we may conclude that having a greater quantity of books in a home will undoubtedly benefit a student's academic performance.

Students are becoming autonomous, adept members and researchers as they advance in technology and usage of computers and the internet. However, let us investigate if having a computer with internet access at the age of 15 has a positive or negative impact on student academic achievement. We will plot the average math results of the several nations that participated in the PISA experiment in 2018 to determine the effect of owning a computer and having access to the internet. This necessitates the creation of a data frame that is grouped by the nations and the frequency of or whether the student possesses a computer or not, as well as whether the student has access to the internet or not. We will plot this result against the weighted average mathematical score to determine the influence of various of television and internet on the student academic performance.


```{r}
int_math_read_sci_data <- student_country_data %>% 
  group_by(country_name, internet) %>% 
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE), 
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE), 
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>% 
  na.omit() 

comp_math_read_sci_data <- student_country_data %>% 
  group_by(country_name, computer) %>% 
  dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE), 
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE), 
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>% 
  na.omit() 


computer_plot <- comp_math_read_sci_data %>%
  ggplot(aes(x=computer, 
             y= math_avg, 
             group = country_name)) +
    geom_point(color = "black",
               size=0.36) +
    geom_line(size = .27, 
              alpha = .45) +
    theme(legend.position = "none") +
    labs(x = "Possession of Computer",
         y = "Average Mathematics Score")


internet_plot <- int_math_read_sci_data %>%
  ggplot(aes(x=internet, 
             y= math_avg, 
             group = country_name )) +
    geom_point(color = "black",
               size=0.36) +
    geom_line(size = .27, 
              alpha = .45) +
    theme(legend.position = "none") +
    labs(x = "Access to Internet",
         y = "Average Mathematics Score")
```



```{r compint-plot, fig.cap ="Computers and the Internet are two of the most important inventions in the history of technology. In this figure, we observe the impact of owning a computer and having access to the internet on 15-year-old students all over the world. A remarkable finding from the plot is that all nations have higher scores in student performance when they own a computer and have access to the internet.",  fig.pos = "H", out.width="100%", layout="l-body"}
computer_plot + internet_plot
```

In the figure \@ref(fig:compint-plot), we see some absolutely fascinating and astonishing insights that might help education policymakers make decisions. This data allows us to conclude that students who own a computer and have access to the internet consistently outperform students who do not own a computer or have access to the internet at all. Interestingly, we regard these as actionable information for all countries participating in the PISA study in 2018. No country was exempt from this findings. Thus, a 15-year-old student's access to a computer and the internet is unquestionably has significant positive influence on their academic performance.

# Temoral Trend Australia 

```{r}
student_all <- load_student("all")


#Australia data
student_country_aus <- left_join(student_all,
                                  countrycode,
                                  by = "country") %>% 
  dplyr::filter(country_name == "Australia") %>%
  group_by(year) %>%
  ungroup() %>% 
  dplyr::select(year, country_name, math, read, science, stu_wgt) %>% 
  na.omit() %>% 
  ungroup()

#nz data
student_country_nz <- left_join(student_all,
                                  countrycode,
                                  by = "country") %>% 
  dplyr::filter(country_name == "New Zealand") %>%
  group_by(year) %>%
  ungroup() %>% 
  dplyr::select(year, country_name, math, read, science, stu_wgt) %>% 
  na.omit() %>% 
  ungroup()

#qatar data
student_country_qat <- left_join(student_all,
                                  countrycode,
                                  by = "country") %>% 
  dplyr::filter(country_name == "Qatar") %>%
  group_by(year) %>%
  ungroup() %>% 
  dplyr::select(year, country_name, math, read, science, stu_wgt) %>% 
  na.omit() %>% 
  ungroup()


#indonesia data
student_country_ind <- left_join(student_all,
                                  countrycode,
                                  by = "country") %>% 
  dplyr::filter(country_name == "Indonesia") %>%
  group_by(year) %>%
  ungroup() %>% 
  dplyr::select(year, country_name, math, read, science, stu_wgt) %>% 
  na.omit() %>% 
  ungroup()

```



```{r}
# Aus bootstrap
aus_bootstrap <- map_dfr(1:100, ~{
student_country_aus %>%
sample_n(size = n(), replace = TRUE) %>%
group_by(country_name, year) %>%
dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>% 
ungroup() %>%
mutate(boot_id = .x)
})


aus_bootsrap_conf_intervlas <- aus_bootstrap %>%
group_by(country_name, year) %>% 
summarise(
lower_math_avg = sort(math_avg)[5],
upper_math_avg = sort(math_avg)[95], 
lower_read_avg = sort(read_avg)[5],
upper_read_avg = sort(read_avg)[95],
lower_sci_avg = sort(sci_avg)[5],
upper_sci_avg = sort(sci_avg)[95])

aus_bs_cf <- left_join(aus_bootstrap,
                      aus_bootsrap_conf_intervlas,
                      by = c("year", "country_name"))

math_aus_plot <- ggplot(
  data = aus_bs_cf, 
  aes(x= year, 
      y = math_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_math_avg,
ymax = upper_math_avg)) +
labs(title = "Australia Maths Scores", 
     x = "Year", 
     y = "Maths Average Score") +
  theme_bw()

read_aus_plot <- ggplot(
  data = aus_bs_cf, 
  aes(x= year, 
      y = read_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_read_avg,
ymax = upper_read_avg)) +
labs(title = "Australia Reading Scores", 
     x = "Year", 
     y = "Reading Average Score") +
  theme_bw()

sci_aus_plot <- ggplot(
  data = aus_bs_cf, 
  aes(x= year, 
      y = sci_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_sci_avg,
ymax = upper_sci_avg)) +
labs(title = "Australia Science Scores", 
     x = "Year", 
     y = "Science Average Score") +
  theme_bw()
```

```{r}
#nz boostrap
nz_bootstrap <- map_dfr(1:100, ~{
student_country_nz %>%
sample_n(size = n(), replace = TRUE) %>%
group_by(country_name, year) %>%
dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>% 
ungroup() %>%
mutate(boot_id = .x)
})


nz_bootsrap_conf_intervlas <- nz_bootstrap %>%
group_by(country_name, year) %>% 
summarise(
lower_math_avg = sort(math_avg)[5],
upper_math_avg = sort(math_avg)[95], 
lower_read_avg = sort(read_avg)[5],
upper_read_avg = sort(read_avg)[95],
lower_sci_avg = sort(sci_avg)[5],
upper_sci_avg = sort(sci_avg)[95])

nz_bs_cf <- left_join(nz_bootstrap,
                      nz_bootsrap_conf_intervlas,
                      by = c("year", "country_name"))

math_nz_plot <- ggplot(
  data = nz_bs_cf, 
  aes(x= year, 
      y = math_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_math_avg,
ymax = upper_math_avg)) +
labs(title = "New Zealand Maths Scores", 
     x = "Year", 
     y = "Maths Average Score") +
  theme_bw()

read_nz_plot <- ggplot(
  data = nz_bs_cf, 
  aes(x= year, 
      y = read_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_read_avg,
ymax = upper_read_avg)) +
labs(title = "New Zealand Reading Scores", 
     x = "Year", 
     y = "Reading Average Score") +
  theme_bw()

sci_nz_plot <- ggplot(
  data = nz_bs_cf, 
  aes(x= year, 
      y = sci_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_sci_avg,
ymax = upper_sci_avg)) +
labs(title = "New Zealand Science Scores", 
     x = "Year", 
     y = "Science Average Score") +
  theme_bw()
```


```{r}
#qat boostrap
qat_bootstrap <- map_dfr(1:100, ~{
student_country_qat %>%
sample_n(size = n(), replace = TRUE) %>%
group_by(country_name, year) %>%
dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>% 
ungroup() %>%
mutate(boot_id = .x)
})


qat_bootsrap_conf_intervlas <- qat_bootstrap %>%
group_by(country_name, year) %>% 
summarise(
lower_math_avg = sort(math_avg)[5],
upper_math_avg = sort(math_avg)[95], 
lower_read_avg = sort(read_avg)[5],
upper_read_avg = sort(read_avg)[95],
lower_sci_avg = sort(sci_avg)[5],
upper_sci_avg = sort(sci_avg)[95])

qat_bs_cf <- left_join(qat_bootstrap,
                      qat_bootsrap_conf_intervlas,
                      by = c("year", "country_name"))

math_qat_plot <- ggplot(
  data = qat_bs_cf, 
  aes(x= year, 
      y = math_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_math_avg,
ymax = upper_math_avg)) +
labs(title = "Qatar Maths Scores", 
     x = "Year", 
     y = "Maths Average Score") +
  theme_bw()

read_qat_plot <- ggplot(
  data = qat_bs_cf, 
  aes(x= year, 
      y = read_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_read_avg,
ymax = upper_read_avg)) +
labs(title = "Qatar Reading Scores", 
     x = "Year", 
     y = "Reading Average Score") +
  theme_bw()

sci_qat_plot <- ggplot(
  data = qat_bs_cf, 
  aes(x= year, 
      y = sci_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_sci_avg,
ymax = upper_sci_avg)) +
labs(title = "Qatar Science Scores", 
     x = "Year", 
     y = "Science Average Score") +
  theme_bw()
```

```{r}
#ind boostrap
ind_bootstrap <- map_dfr(1:100, ~{
student_country_ind %>%
sample_n(size = n(), replace = TRUE) %>%
group_by(country_name, year) %>%
dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>% 
ungroup() %>%
mutate(boot_id = .x)
})


ind_bootsrap_conf_intervlas <- ind_bootstrap %>%
group_by(country_name, year) %>% 
summarise(
lower_math_avg = sort(math_avg)[5],
upper_math_avg = sort(math_avg)[95], 
lower_read_avg = sort(read_avg)[5],
upper_read_avg = sort(read_avg)[95],
lower_sci_avg = sort(sci_avg)[5],
upper_sci_avg = sort(sci_avg)[95])

ind_bs_cf <- left_join(ind_bootstrap,
                      ind_bootsrap_conf_intervlas,
                      by = c("year", "country_name"))

math_ind_plot <- ggplot(
  data = ind_bs_cf, 
  aes(x= year, 
      y = math_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_math_avg,
ymax = upper_math_avg)) +
labs(title = "Indonesia Maths Scores", 
     x = "Year", 
     y = "Maths Average Score") +
  theme_bw()

read_ind_plot <- ggplot(
  data = ind_bs_cf, 
  aes(x= year, 
      y = read_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_read_avg,
ymax = upper_read_avg)) +
labs(title = "Indonesia Reading Scores", 
     x = "Year", 
     y = "Reading Average Score") +
  theme_bw()

sci_ind_plot <- ggplot(
  data = ind_bs_cf, 
  aes(x= year, 
      y = sci_avg)) +
  geom_point(alpha = 0.1) +
geom_errorbar(aes(x= year,
ymin = lower_sci_avg,
ymax = upper_sci_avg)) +
labs(title = "Indonesia Science Scores", 
     x = "Year", 
     y = "Science Average Score") +
  theme_bw()
```

```{r bs-plot, eval = knitr::is_latex_output(), fig.cap ="Bootstrap", fig.pos = "H", fig.width = 20, fig.height=18, out.width="100%"}
math_aus_plot + read_aus_plot + sci_aus_plot/
math_nz_plot + read_nz_plot + sci_nz_plot/
math_qat_plot + read_qat_plot + sci_qat_plot/
math_ind_plot + read_ind_plot + sci_ind_plot
```


# Animations


```{r anim-plot, eval = knitr::is_html_output(), fig.cap ="Bootstrap Animation", fig.pos = "H", out.width="100%", layout="l-body-outset"}
student_country_anim <- left_join(student_all,
                                  countrycode,
                                  by = "country") %>%
  dplyr::filter(country_name %in% c("Australia",
                                    "Finland",
                                    "United States",
                                    "Peru",
                                    "Qatar",
                                    "Morocco",
                                    "Indonesia", 
                                    "Brazil",
                                    "Thailand", 
                                    "Singapore")) %>%
  group_by(year) %>%
  ungroup() %>%
  dplyr::select(year, country_name, math, read, science, stu_wgt) %>%
  na.omit()

student_country_anim_avg <- student_country_anim %>%
group_by(country_name, year) %>%
dplyr::summarise(math_avg = weighted.mean(math, w = stu_wgt, na.rm = TRUE),
                   read_avg = weighted.mean(read, w = stu_wgt, na.rm = TRUE),
                   sci_avg  =  weighted.mean(science, w = stu_wgt, na.rm = TRUE)) %>%
ungroup() %>%
rename(`Country Name` = country_name)

student_country_anim_avg$year <- as.numeric(student_country_anim_avg$year)

#animate
ggplot(student_country_anim_avg,
       aes(math_avg, sci_avg,
           color = `Country Name`)) +
  geom_point(size = 6.3, alpha = 0.54) +
  scale_size(range = c(2, 12)) +
  theme_bw() +
  transition_time(year) +
  ease_aes('linear') +
  labs(title = "Animation", 
       x = "Average Maths Scores",
       y = "Average Science Scores")
```

Figure `r knitr::asis_output(ifelse(knitr::is_html_output(), '\\@ref(fig:anim-plot)', '\\@ref(fig:bs-plot)'))`


# Discussion



